# Industrial Multi-Agent System with LangGraph

> EndÃ¼striyel seviyede TÃ¼rkÃ§e Ã§ok-ajanlÄ± yapay zeka sistemi â€” LangGraph + Turkish-Gemma-9b

**v2.0** Â· Python 3.10+ Â· LangGraph Â· HuggingFace Transformers

---

## Ã–zellikler

- ğŸ—ºï¸ **Planner Agent** â€” Sorguyu analiz eder, gÃ¶rev tipi ve adÄ±mlarÄ± belirler (JSON plan)
- ğŸ”€ **Router Agent** â€” Plana gÃ¶re iÅŸ akÄ±ÅŸÄ±nÄ± doÄŸru ajana yÃ¶nlendirir
- ğŸ“š **Wikipedia Entegrasyonu** â€” TÃ¼rkÃ§e Wikipedia'da iki aÅŸamalÄ± arama ve iÃ§erik Ã§ekme
- ğŸ“ **Summarizer Agent** â€” Uzun Wikipedia iÃ§eriÄŸini soruya odaklÄ± yoÄŸunlaÅŸtÄ±rÄ±r
- ğŸ§® **Math Agent** â€” AdÄ±m adÄ±m matematiksel hesaplama
- ğŸ’¬ **Chat Agent** â€” KonuÅŸma geÃ§miÅŸine duyarlÄ± doÄŸal TÃ¼rkÃ§e sohbet
- ğŸ” **QA Checker Agent** â€” 0-10 kalite skoru + otomatik yeniden deneme dÃ¶ngÃ¼sÃ¼
- ğŸ§  **Conversation Memory** â€” Kayan pencereli konuÅŸma geÃ§miÅŸi (son 6 tur)
- âš™ï¸ **System Logger** â€” Zaman damgalÄ± yapÄ±landÄ±rÄ±lmÄ±ÅŸ yÃ¼rÃ¼tme izi
- âš¡ **4-bit Kuantizasyon** â€” BitsAndBytes NF4 ile verimli VRAM kullanÄ±mÄ±

---

## Mimari

```
INPUT
  â†“
ğŸ—ºï¸  PlannerAgent       â†’ JSON plan Ã¼retir (task_type, steps, intentâ€¦)
  â†“
ğŸ”€  RouterAgent        â†’ research | math | chat
  â†“
  â”Œâ”€â”€ ğŸ“š WikiSearchAgent  â†’ wiki_raw{}
  â”‚      â†“
  â”‚   ğŸ“ SummarizerAgent  â†’ wiki_summary  [koÅŸullu]
  â”‚
  â”œâ”€â”€ ğŸ§® MathAgent        â†’ math_result
  â”‚
  â””â”€â”€ ğŸ’¬ ChatAgent        â†’ (pass-through)
       â†“
âœï¸  AnswerGeneratorAgent  â†’ draft_answer
  â†“
ğŸ”  QualityCheckerAgent   â†’ qa_report + final_answer
  â”‚
  â”œâ”€â”€ skor â‰¥ 6 â†’ END âœ…
  â””â”€â”€ skor < 6 â†’ answer_gen (max 2 retry) ğŸ”„
```

Tam gÃ¶rsel dokÃ¼mantasyon: [`docs/system_architecture.html`](docs/system_architecture.html)

---

## Kurulum

### Gereksinimler

- Python 3.10+
- CUDA destekli GPU (Ã¶nerilen)
- 8 GB+ VRAM (4-bit kuantizasyon ile)

### BaÄŸÄ±mlÄ±lÄ±klar

```bash
git clone https://github.com/yourusername/LangGraph-Agent.git
cd LangGraph-Agent
pip install -r requirements.txt
```

---

## KullanÄ±m

```bash
python agent.py
```

### Ã–rnek EtkileÅŸimler

```
ğŸ§‘  Sorgu: AtatÃ¼rk kimdir?
  ğŸ—ºï¸ [PLANNER   ] Plan â†’ task_type: research, requires_summary: true
  ğŸ”€ [ROUTER    ] research â†’ wiki
  ğŸ“š [WIKI      ] Bulundu: 'Mustafa Kemal AtatÃ¼rk' (4200 karakter)
  ğŸ“ [SUMMARIZER] Ã–zet Ã¼retildi: 480 karakter
  âœï¸  [ANSWER    ] AraÅŸtÄ±rma cevabÄ± Ã¼retildi
  ğŸ” [QA        ] Kalite skoru: 8/10 | OnaylÄ±: True
ğŸ¤–  Mustafa Kemal AtatÃ¼rk, TÃ¼rkiye Cumhuriyeti'nin kurucusu...

ğŸ§‘  Sorgu: 144'Ã¼n karekÃ¶kÃ¼ kaÃ§tÄ±r?
  ğŸ—ºï¸ [PLANNER   ] Plan â†’ task_type: math
  ğŸ”€ [ROUTER    ] math â†’ math
  ğŸ§® [MATH      ] Hesaplama tamamlandÄ±
  ğŸ” [QA        ] Kalite skoru: 9/10 | OnaylÄ±: True
ğŸ¤–  âˆš144 = 12

ğŸ§‘  Sorgu: Merhaba!
  ğŸ—ºï¸ [PLANNER   ] Plan â†’ task_type: chat
  ğŸ’¬ [CHAT      ] â†’ answer_gen
  ğŸ” [QA        ] Kalite skoru: 7/10 | OnaylÄ±: True
ğŸ¤–  Merhaba! Size nasÄ±l yardÄ±mcÄ± olabilirim?
```

---

## Teknik Detaylar

### Model

| Parametre | DeÄŸer |
|---|---|
| Model | `ytu-ce-cosmos/Turkish-Gemma-9b-v0.1` |
| Kuantizasyon | 4-bit BitsAndBytes (NF4, double_quant) |
| compute_dtype | `torch.float16` |
| Framework | PyTorch + HuggingFace Transformers |

### AgentState AlanlarÄ±

| Alan | Tip | AÃ§Ä±klama |
|---|---|---|
| `session_id` | str | UUID v4 tabanlÄ± 8 karakter oturum kimliÄŸi |
| `user_query` | str | Ham kullanÄ±cÄ± sorgusu |
| `conversation_history` | List | ConversationMemory'den gelen geÃ§miÅŸ |
| `plan` | Dict | PlannerAgent Ã§Ä±ktÄ±sÄ± |
| `wiki_raw` | Dict | Ham Wikipedia verisi |
| `wiki_summary` | str | Ã–zetlenmiÅŸ Wikipedia iÃ§eriÄŸi |
| `math_result` | str | Matematiksel hesaplama Ã§Ä±ktÄ±sÄ± |
| `draft_answer` | str | QA Ã¶ncesi taslak cevap |
| `final_answer` | str | QA onaylÄ± nihai cevap |
| `qa_report` | Dict | Kalite raporu (skor, sorunlar, gerekÃ§e) |
| `retry_count` | int | Yeniden deneme sayacÄ± (max: 2) |
| `execution_trace` | List | AdÄ±m adÄ±m yÃ¼rÃ¼tme log kayÄ±tlarÄ± |
| `error_log` | List | AraÃ§ hatalarÄ± |

### Sistem Limitleri

| Sabit | DeÄŸer |
|---|---|
| `MAX_RETRY_ATTEMPTS` | 2 |
| `QUALITY_THRESHOLD` | 6 / 10 |
| `MEMORY_WINDOW` | 6 tur |
| `WIKI_SUMMARY_MAX_CHARS` | 1200 |
| `WIKI_CONDENSED_MAX_CHARS` | 500 |

---

## Performans

RTX 4060 Ti SUPER, 4-bit kuantizasyon:

| Ajan | Ortalama SÃ¼re | Not |
|---|---|---|
| Chat Agent | ~7-8 s | DoÄŸrudan LLM Ã§Ä±karÄ±mÄ± |
| Math Agent | ~9-11 s | LLM tabanlÄ± hesaplama |
| Wiki Agent (Ã¶zetli) | ~35-45 s | Wikipedia API (~15-20 s) + Summarizer |
| Wiki Agent (Ã¶zetsiz) | ~30-35 s | Wikipedia API + Answer Gen |

**VRAM KullanÄ±mÄ±:** ~8 GB (4-bit kuantizasyon)

---

## Proje YapÄ±sÄ±

```
LangGraph-Agent/
â”œâ”€â”€ agent.py                    # Ana sistem (tÃ¼m ajanlar)
â”œâ”€â”€ requirements.txt            # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ README.md                   # Bu dosya
â””â”€â”€ docs/
    â””â”€â”€ system_architecture.html  # GÃ¶rsel mimari dokÃ¼mantasyon
```

---

## Kaynaklar

- [Turkish-Gemma-9b â€” YTU CE Cosmos Lab](https://huggingface.co/ytu-ce-cosmos/Turkish-Gemma-9b-v0.1)
- [LangGraph â€” LangChain](https://github.com/langchain-ai/langgraph)
- [TÃ¼rkÃ§e Wikipedia API](https://tr.wikipedia.org/w/api.php)
- [Cosmos Lab](https://cosmos.yildiz.edu.tr/)
