"""
Industrial-Grade Multi-Agent System with LangGraph
===================================================
Agents:
  - PlannerAgent       : GÃ¶rev analizi ve Ã§ok adÄ±mlÄ± plan Ã¼retimi
  - RouterAgent        : Plana gÃ¶re iÅŸ akÄ±ÅŸÄ± yÃ¶nlendirme
  - WikiSearchAgent    : TÃ¼rkÃ§e Wikipedia araÅŸtÄ±rma
  - SummarizerAgent    : Uzun iÃ§erikleri yoÄŸunlaÅŸtÄ±rma
  - MathAgent          : Matematiksel hesaplamalar
  - ChatAgent          : Sohbet / genel konuÅŸma
  - AnswerGeneratorAgent: Nihai cevap Ã¼retimi
  - QualityCheckerAgent: Kalite skoru + otomatik yeniden deneme
  - ConversationMemory : KonuÅŸma geÃ§miÅŸi yÃ¶netimi
  - SystemLogger       : YapÄ±landÄ±rÄ±lmÄ±ÅŸ log + yÃ¼rÃ¼tme izi
"""

from __future__ import annotations

import json
import re
import textwrap
import time
import uuid
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, TypedDict

import requests
import torch
from langgraph.graph import END, StateGraph
from langgraph.graph.state import CompiledStateGraph
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Konfigurasyon
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_ID = "ytu-ce-cosmos/Turkish-Gemma-9b-v0.1"
USE_4BIT_QUANTIZATION = True
MAX_RETRY_ATTEMPTS = 2
QUALITY_THRESHOLD = 6       # 0-10 skalasÄ±nda minimum kalite skoru
MEMORY_WINDOW = 6           # HafÄ±zada tutulacak maksimum tur sayÄ±sÄ±
WIKI_SUMMARY_MAX_CHARS = 1200
WIKI_CONDENSED_MAX_CHARS = 500


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Durum (State) TanÄ±mÄ±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AgentState(TypedDict):
    """LangGraph boyunca taÅŸÄ±nan merkezi durum nesnesi."""
    session_id: str
    user_query: str
    conversation_history: List[Dict[str, str]]

    # Planner Ã§Ä±ktÄ±sÄ±
    plan: Optional[Dict[str, Any]]

    # AraÃ§ Ã§Ä±ktÄ±larÄ±
    wiki_raw: Optional[Dict[str, str]]
    wiki_summary: Optional[str]
    math_result: Optional[str]

    # Cevap Ã¼retimi
    draft_answer: Optional[str]
    final_answer: Optional[str]

    # Kalite kontrol
    qa_report: Optional[Dict[str, Any]]
    retry_count: int

    # Ä°zleme
    execution_trace: List[str]
    error_log: List[str]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sistem Logger
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SystemLogger:
    """Renkli, yapÄ±landÄ±rÄ±lmÄ±ÅŸ konsol logu."""

    ICONS = {
        "planner":   "ğŸ—ºï¸ ",
        "router":    "ğŸ”€",
        "wiki":      "ğŸ“š",
        "summarizer":"ğŸ“",
        "math":      "ğŸ§®",
        "chat":      "ğŸ’¬",
        "answer":    "âœï¸ ",
        "qa":        "ğŸ”",
        "memory":    "ğŸ§ ",
        "system":    "âš™ï¸ ",
        "ok":        "âœ…",
        "warn":      "âš ï¸ ",
        "error":     "âŒ",
        "retry":     "ğŸ”„",
    }

    @staticmethod
    def log(agent: str, message: str) -> str:
        icon = SystemLogger.ICONS.get(agent, "â€¢")
        ts = time.strftime("%H:%M:%S")
        line = f"[{ts}] {icon} [{agent.upper():12s}] {message}"
        print(line)
        return line

    @staticmethod
    def separator(title: str = "", width: int = 70):
        if title:
            pad = (width - len(title) - 2) // 2
            print("â”€" * pad + f" {title} " + "â”€" * pad)
        else:
            print("â”€" * width)

    @staticmethod
    def header(title: str, width: int = 70):
        print("\n" + "â•" * width)
        print(f"  {title}")
        print("â•" * width)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# KonuÅŸma HafÄ±zasÄ±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class ConversationMemory:
    """Kayan pencereli konuÅŸma geÃ§miÅŸi yÃ¶neticisi."""

    def __init__(self, window: int = MEMORY_WINDOW):
        self.window = window
        self._turns: List[Dict[str, str]] = []

    def add(self, role: str, content: str):
        self._turns.append({"role": role, "content": content})
        if len(self._turns) > self.window * 2:
            self._turns = self._turns[-(self.window * 2):]

    def get_context(self) -> str:
        """Son N turu metin olarak dÃ¶ndÃ¼r."""
        if not self._turns:
            return "HenÃ¼z konuÅŸma geÃ§miÅŸi yok."
        lines = []
        for t in self._turns[-self.window * 2:]:
            prefix = "KullanÄ±cÄ±" if t["role"] == "user" else "Asistan"
            lines.append(f"{prefix}: {t['content']}")
        return "\n".join(lines)

    def as_list(self) -> List[Dict[str, str]]:
        return list(self._turns)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Model YÃ¼kleyici
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class ModelLoader:
    @staticmethod
    def load(model_id: str = MODEL_ID, use_4bit: bool = USE_4BIT_QUANTIZATION):
        tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)

        if use_4bit:
            qcfg = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_compute_dtype=torch.float16,
                bnb_4bit_quant_type="nf4",
                bnb_4bit_use_double_quant=True,
            )
            model = AutoModelForCausalLM.from_pretrained(
                model_id,
                device_map="auto",
                quantization_config=qcfg,
                torch_dtype=torch.float16,
            )
        else:
            dtype = torch.float16 if torch.cuda.is_available() else torch.float32
            model = AutoModelForCausalLM.from_pretrained(
                model_id, device_map="auto", torch_dtype=dtype
            )

        model.eval()
        return tokenizer, model


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM Motoru
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class LLMEngine:
    """Dil modeli Ã§Ä±karÄ±m motoru."""

    def __init__(self, tokenizer, model):
        self.tokenizer = tokenizer
        self.model = model

    def _terminators(self):
        terms = [self.tokenizer.eos_token_id]
        eot = self.tokenizer.convert_tokens_to_ids("<end_of_turn>")
        if isinstance(eot, int) and eot != self.tokenizer.unk_token_id:
            terms.append(eot)
        return terms

    @torch.inference_mode()
    def generate(self, messages: List[Dict], max_new_tokens: int = 256) -> str:
        prompt = self.tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
        outputs = self.model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            do_sample=False,
            repetition_penalty=1.05,
            eos_token_id=self._terminators(),
            pad_token_id=self.tokenizer.eos_token_id,
        )
        gen = outputs[0][inputs["input_ids"].shape[1]:]
        return self.tokenizer.decode(gen, skip_special_tokens=True).strip()

    def chat(self, system_prompt: str, user_prompt: str,
             max_new_tokens: int = 256, history: Optional[List[Dict]] = None) -> str:
        messages = [{"role": "system", "content": system_prompt}]
        if history:
            messages.extend(history)
        messages.append({"role": "user", "content": user_prompt})
        return self.generate(messages, max_new_tokens)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Wikipedia ArayÄ±cÄ±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class WikipediaSearcher:
    API_URL = "https://tr.wikipedia.org/w/api.php"
    TIMEOUT = 15

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "IndustrialAgentSystem/2.0 (LangGraph; Turkish NLP)"
        })

    def search(self, query: str) -> Optional[Dict[str, str]]:
        try:
            cleaned = re.sub(r"\b(kimdir|nedir|hakkÄ±nda|ne zaman|nerede)\b",
                             "", query, flags=re.IGNORECASE).strip() or query
            SystemLogger.log("wiki", f"AranÄ±yor: '{cleaned}'")

            title = self._find_title(cleaned)
            if not title:
                return None

            return self._fetch(title)
        except Exception as e:
            SystemLogger.log("error", f"Wikipedia hatasÄ±: {e}")
            return None

    def _find_title(self, query: str) -> Optional[str]:
        params = {
            "action": "query", "list": "search",
            "srsearch": query, "format": "json", "srlimit": 1
        }
        r = self.session.get(self.API_URL, params=params, timeout=self.TIMEOUT)
        r.raise_for_status()
        results = r.json().get("query", {}).get("search", [])
        return results[0]["title"] if results else None

    def _fetch(self, title: str) -> Optional[Dict[str, str]]:
        params = {
            "action": "query", "prop": "extracts|info",
            "exintro": True, "explaintext": True,
            "titles": title, "format": "json", "inprop": "url"
        }
        r = self.session.get(self.API_URL, params=params, timeout=self.TIMEOUT)
        r.raise_for_status()
        pages = r.json().get("query", {}).get("pages", {})
        page = list(pages.values())[0]
        extract = page.get("extract", "")
        if not extract:
            return None
        summary = extract[:WIKI_SUMMARY_MAX_CHARS] + ("â€¦" if len(extract) > WIKI_SUMMARY_MAX_CHARS else "")
        return {
            "title": title,
            "summary": summary,
            "url": page.get("fullurl", ""),
            "char_count": str(len(extract))
        }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ajan Ä°stem KitaplÄ±ÄŸÄ±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Prompts:
    PLANNER = """\
Sen bir gÃ¶rev planlama ajanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorgusunu analiz et ve JSON planÄ± Ã¼ret.

PLAN ÅEMASI:
{
  "task_type": "<research|math|chat>",
  "steps": ["<adÄ±m1>", "<adÄ±m2>", ...],
  "search_query": "<Wikipedia arama terimi veya boÅŸ>",
  "requires_summary": <true|false>,
  "complexity": "<low|medium|high>",
  "language": "tr",
  "intent": "<kullanÄ±cÄ± niyetinin kÄ±sa aÃ§Ä±klamasÄ±>"
}

KURALLAR:
- AraÅŸtÄ±rma/bilgi sorusu â†’ task_type: "research", steps: ["search_wiki","summarize","generate_answer"]
- Matematik â†’ task_type: "math", steps: ["calculate","generate_answer"]
- Selamlama/sohbet â†’ task_type: "chat", steps: ["generate_answer"]
- requires_summary: Wikipedia sonucu uzunsa (complexity medium/high) true
- YalnÄ±zca JSON Ã§Ä±ktÄ±sÄ± ver.
"""

    ROUTER = """\
Plan doÄŸrultusunda yÃ¶nlendir. Sadece tek kelimeyle yanÄ±t ver:
  research  â†’ wiki aramasÄ± gerekiyor
  math      â†’ matematik hesabÄ± gerekiyor
  chat      â†’ doÄŸrudan sohbet
"""

    SUMMARIZER = """\
Sen bir iÃ§erik Ã¶zetleme uzmanÄ±sÄ±n. Verilen Wikipedia metnini sÄ±kÄ±ÅŸtÄ±r.

KURALLAR:
- En Ã¶nemli 4-6 bilgiyi madde madde listele
- Her madde 1-2 cÃ¼mle
- Anahtar kavramlarÄ±, tarihleri, isimleri koru
- TÃ¼rkÃ§e yaz
- Gereksiz detaylarÄ± at
"""

    ANSWER_GENERATOR = """\
Sen uzman bir asistansÄ±n. Plandan ve toplanan verilerden yararlanarak kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tla.

KURALLAR:
- Ã–zetlenmiÅŸ bilgiyi kullan, ham veri yerine
- 5-8 cÃ¼mle, akÄ±cÄ± paragraf
- Kaynak belirt (Wikipedia varsa)
- TÃ¼rkÃ§e, aÃ§Ä±k ve doÄŸru yaz
- BilmediÄŸin ÅŸeyi uydurma
"""

    MATH = """\
Sen bir matematik asistanÄ±sÄ±n.

KURALLAR:
- Verilen ifadeyi hesapla
- AdÄ±m adÄ±m Ã§Ã¶zÃ¼m gÃ¶ster
- Sonucu "SonuÃ§: <deÄŸer>" formatÄ±nda sun
- TÃ¼rkÃ§e yaz
"""

    CHAT = """\
Sen samimi ve yardÄ±msever bir asistansÄ±n. KullanÄ±cÄ±yla doÄŸal TÃ¼rkÃ§e konuÅŸma yap.

KURALLAR:
- KÄ±sa ve iÃ§ten yanÄ±t ver
- KonuÅŸma geÃ§miÅŸini dikkate al
- TÃ¼rkÃ§e yaz
"""

    QA_CHECKER = """\
Sen bir kalite kontrol ajanÄ±sÄ±n. Ãœretilen cevabÄ± deÄŸerlendir ve JSON raporu ver.

RAPOR ÅEMASI:
{
  "quality_score": <0-10 tam sayÄ±>,
  "issues": ["<sorun1>", ...],
  "suggestions": ["<Ã¶neri1>", ...],
  "approved": <true|false>,
  "reasoning": "<kÄ±sa deÄŸerlendirme>"
}

DEÄERLENDÄ°RME KRÄ°TERLERÄ°:
- Soruyla ilgililik (0-3)
- DoÄŸruluk ve tutarlÄ±lÄ±k (0-3)
- AnlaÅŸÄ±lÄ±rlÄ±k ve akÄ±cÄ±lÄ±k (0-2)
- YanÄ±ltÄ±cÄ± veya boÅŸ iÃ§erik cezasÄ± (-2)

approved = true ise quality_score >= 6 olmalÄ±.
YalnÄ±zca JSON Ã§Ä±ktÄ±sÄ± ver.
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ajan UygulamalarÄ±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class PlannerAgent:
    """Gelen sorguyu analiz eder ve Ã§ok adÄ±mlÄ± yÃ¼rÃ¼tme planÄ± Ã¼retir."""

    def __init__(self, llm: LLMEngine):
        self.llm = llm

    def run(self, state: AgentState) -> AgentState:
        trace = state["execution_trace"]
        query = state["user_query"]
        history_ctx = ""
        if state["conversation_history"]:
            last = state["conversation_history"][-4:]
            history_ctx = "\n".join(
                f"{'K' if t['role']=='user' else 'A'}: {t['content']}" for t in last
            )

        user_prompt = f"GeÃ§miÅŸ (son turlar):\n{history_ctx}\n\nMevcut sorgu: {query}"
        raw = self.llm.chat(Prompts.PLANNER, user_prompt, max_new_tokens=200)
        SystemLogger.log("planner", f"Ham plan Ã§Ä±ktÄ±sÄ±: {raw[:120]}â€¦")

        plan = self._parse_plan(raw)
        trace.append(SystemLogger.log("planner", f"Plan â†’ {plan}"))
        return {**state, "plan": plan, "execution_trace": trace}

    @staticmethod
    def _parse_plan(raw: str) -> Dict[str, Any]:
        default = {
            "task_type": "chat",
            "steps": ["generate_answer"],
            "search_query": "",
            "requires_summary": False,
            "complexity": "low",
            "language": "tr",
            "intent": "genel sohbet"
        }
        match = re.search(r'\{.*?\}', raw, flags=re.DOTALL)
        if not match:
            return default
        try:
            plan = json.loads(match.group(0))
            for k, v in default.items():
                plan.setdefault(k, v)
            if plan["task_type"] not in ("research", "math", "chat"):
                plan["task_type"] = "chat"
            return plan
        except json.JSONDecodeError:
            return default


class WikiSearchAgent:
    """Wikipedia'da araÅŸtÄ±rma yapar."""

    def __init__(self, searcher: WikipediaSearcher):
        self.searcher = searcher

    def run(self, state: AgentState) -> AgentState:
        trace = state["execution_trace"]
        errors = state["error_log"]
        query = state["plan"].get("search_query") or state["user_query"]

        result = self.searcher.search(query)
        if result:
            trace.append(SystemLogger.log("wiki", f"Bulundu: '{result['title']}' ({result['char_count']} karakter)"))
        else:
            errors.append("Wikipedia: sonuÃ§ bulunamadÄ±.")
            trace.append(SystemLogger.log("warn", "Wikipedia sonuÃ§ yok"))

        return {**state, "wiki_raw": result, "execution_trace": trace, "error_log": errors}


class SummarizerAgent:
    """Uzun Wikipedia iÃ§eriÄŸini yoÄŸunlaÅŸtÄ±rÄ±r."""

    def __init__(self, llm: LLMEngine):
        self.llm = llm

    def run(self, state: AgentState) -> AgentState:
        trace = state["execution_trace"]
        wiki = state.get("wiki_raw")

        if not wiki:
            trace.append(SystemLogger.log("summarizer", "Ã–zetlenecek iÃ§erik yok, atlanÄ±yor"))
            return {**state, "wiki_summary": None, "execution_trace": trace}

        user_prompt = (
            f"Makale baÅŸlÄ±ÄŸÄ±: {wiki['title']}\n\n"
            f"Ä°Ã§erik:\n{wiki['summary']}\n\n"
            f"KullanÄ±cÄ± sorusu: {state['user_query']}\n\n"
            "LÃ¼tfen bu iÃ§eriÄŸi soruya odaklanarak Ã¶zetle."
        )

        compressed = self.llm.chat(Prompts.SUMMARIZER, user_prompt, max_new_tokens=300)

        if len(compressed) > WIKI_CONDENSED_MAX_CHARS:
            compressed = compressed[:WIKI_CONDENSED_MAX_CHARS] + "â€¦"

        trace.append(SystemLogger.log("summarizer",
            f"Ã–zet Ã¼retildi: {len(compressed)} karakter (orijinal: {len(wiki['summary'])})"))

        return {**state, "wiki_summary": compressed, "execution_trace": trace}


class MathAgent:
    """Matematiksel hesaplamalar gerÃ§ekleÅŸtirir."""

    def __init__(self, llm: LLMEngine):
        self.llm = llm

    def run(self, state: AgentState) -> AgentState:
        trace = state["execution_trace"]
        expr = state["plan"].get("search_query") or state["user_query"]

        user_prompt = f"Ä°fade: {expr}\n\nAdÄ±m adÄ±m Ã§Ã¶z ve sonucu ver."
        result = self.llm.chat(Prompts.MATH, user_prompt, max_new_tokens=200)

        trace.append(SystemLogger.log("math", f"Hesaplama tamamlandÄ±"))
        return {**state, "math_result": result, "execution_trace": trace}


class AnswerGeneratorAgent:
    """Toplanan tÃ¼m verilerden nihai taslak cevap Ã¼retir."""

    def __init__(self, llm: LLMEngine):
        self.llm = llm

    def run(self, state: AgentState) -> AgentState:
        trace = state["execution_trace"]
        plan = state["plan"]
        task_type = plan["task_type"]

        if task_type == "math":
            draft = state.get("math_result") or "Hesaplama sonucu bulunamadÄ±."
            trace.append(SystemLogger.log("answer", "Matematik cevabÄ± iletildi"))
            return {**state, "draft_answer": draft, "execution_trace": trace}

        if task_type == "chat":
            history = state["conversation_history"][-4:] if state["conversation_history"] else []
            draft = self.llm.chat(
                Prompts.CHAT, state["user_query"],
                max_new_tokens=200, history=history
            )
            trace.append(SystemLogger.log("answer", "Sohbet cevabÄ± Ã¼retildi"))
            return {**state, "draft_answer": draft, "execution_trace": trace}

        # research
        summary = state.get("wiki_summary")
        raw = state.get("wiki_raw")
        wiki_info = ""
        if summary:
            wiki_info = f"Ã–zet Bilgi:\n{summary}"
        elif raw:
            wiki_info = f"Ham Bilgi (Ã¶zetsiz):\n{raw['summary'][:600]}"
        else:
            wiki_info = "Wikipedia'da ilgili bilgi bulunamadÄ±."

        user_prompt = (
            f"KullanÄ±cÄ± Sorusu: {state['user_query']}\n\n"
            f"Plan Niyeti: {plan.get('intent', '')}\n\n"
            f"{wiki_info}\n\n"
            + (f"Kaynak: {raw['url']}" if raw else "")
        )
        draft = self.llm.chat(Prompts.ANSWER_GENERATOR, user_prompt, max_new_tokens=380)
        trace.append(SystemLogger.log("answer", "AraÅŸtÄ±rma cevabÄ± Ã¼retildi"))
        return {**state, "draft_answer": draft, "execution_trace": trace}


class QualityCheckerAgent:
    """Taslak cevabÄ±n kalitesini deÄŸerlendirir; dÃ¼ÅŸÃ¼k skorlarda yeniden deneme tetikler."""

    def __init__(self, llm: LLMEngine):
        self.llm = llm

    def run(self, state: AgentState) -> AgentState:
        trace = state["execution_trace"]
        draft = state.get("draft_answer", "")
        retry = state.get("retry_count", 0)

        user_prompt = (
            f"KullanÄ±cÄ± Sorusu: {state['user_query']}\n\n"
            f"Ãœretilen Cevap:\n{draft}\n\n"
            "Bu cevabÄ± yukarÄ±daki kriterlere gÃ¶re deÄŸerlendir."
        )
        raw = self.llm.chat(Prompts.QA_CHECKER, user_prompt, max_new_tokens=200)
        report = self._parse_report(raw)

        score = report.get("quality_score", 0)
        approved = report.get("approved", False)

        trace.append(SystemLogger.log("qa",
            f"Kalite skoru: {score}/10 | OnaylÄ±: {approved} | "
            f"Sorunlar: {report.get('issues', [])}"))

        if not approved and retry < MAX_RETRY_ATTEMPTS:
            trace.append(SystemLogger.log("retry", f"Yeniden deneme #{retry + 1} tetikleniyor"))
            return {
                **state,
                "qa_report": report,
                "retry_count": retry + 1,
                "draft_answer": None,
                "execution_trace": trace,
            }

        final = draft
        if not approved:
            final = (
                f"{draft}\n\n"
                f"âš ï¸ Not: Bu yanÄ±t kalite eÅŸiÄŸinin altÄ±nda kalabilir "
                f"(skor: {score}/10). LÃ¼tfen bilgileri teyit edin."
            )
            trace.append(SystemLogger.log("warn", "DÃ¼ÅŸÃ¼k kaliteli cevap uyarÄ±yla yayÄ±mlandÄ±"))

        return {**state, "qa_report": report, "final_answer": final, "execution_trace": trace}

    @staticmethod
    def _parse_report(raw: str) -> Dict[str, Any]:
        default = {
            "quality_score": 5,
            "issues": [],
            "suggestions": [],
            "approved": True,
            "reasoning": "DeÄŸerlendirme ayrÄ±ÅŸtÄ±rÄ±lamadÄ±"
        }
        match = re.search(r'\{.*?\}', raw, flags=re.DOTALL)
        if not match:
            return default
        try:
            report = json.loads(match.group(0))
            for k, v in default.items():
                report.setdefault(k, v)
            return report
        except json.JSONDecodeError:
            return default


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ana OrkestratÃ¶r
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AgentOrchestrator:
    """
    LangGraph tabanlÄ± endÃ¼striyel ajan sistemi.

    Graf AkÄ±ÅŸÄ±:
        planner â†’ router â†’ â”¬â”€ wiki â†’ summarizer â”€â”
                           â”œâ”€ math               â”€â”¤â†’ answer_gen â†’ qa_checker â†’ END
                           â””â”€ chat              â”€â”˜
        qa_checker â†’ answer_gen  (kalite baÅŸarÄ±sÄ±z + retry hakkÄ± varsa)
    """

    def __init__(
        self,
        llm: LLMEngine,
        wiki: WikipediaSearcher,
        memory: ConversationMemory,
    ):
        self.llm = llm
        self.wiki = wiki
        self.memory = memory

        self.planner   = PlannerAgent(llm)
        self.searcher  = WikiSearchAgent(wiki)
        self.summarizer= SummarizerAgent(llm)
        self.math      = MathAgent(llm)
        self.answer    = AnswerGeneratorAgent(llm)
        self.qa        = QualityCheckerAgent(llm)

        self.app = self._build_graph()

    # â”€â”€ Graf inÅŸasÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _build_graph(self) -> CompiledStateGraph:
        g = StateGraph(AgentState)

        g.add_node("planner",     self.planner.run)
        g.add_node("router",      self._router_node)
        g.add_node("wiki",        self.searcher.run)
        g.add_node("summarizer",  self._conditional_summarizer)
        g.add_node("math",        self.math.run)
        g.add_node("chat",        self._chat_node)
        g.add_node("answer_gen",  self.answer.run)
        g.add_node("qa_checker",  self.qa.run)

        g.set_entry_point("planner")
        g.add_edge("planner", "router")

        g.add_conditional_edges(
            "router", self._route_decision,
            {"wiki": "wiki", "math": "math", "chat": "chat"}
        )

        g.add_edge("wiki",   "summarizer")
        g.add_edge("math",   "answer_gen")
        g.add_edge("chat",   "answer_gen")
        g.add_edge("summarizer", "answer_gen")

        g.add_edge("answer_gen", "qa_checker")

        g.add_conditional_edges(
            "qa_checker", self._qa_decision,
            {"approved": END, "retry": "answer_gen"}
        )

        return g.compile()

    # â”€â”€ Ara DÃ¼ÄŸÃ¼mler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _router_node(self, state: AgentState) -> AgentState:
        task = state["plan"]["task_type"]
        route_map = {"research": "wiki", "math": "math", "chat": "chat"}
        route = route_map.get(task, "chat")
        trace = state["execution_trace"]
        trace.append(SystemLogger.log("router", f"YÃ¶nlendirme: {task} â†’ {route}"))
        return {**state, "execution_trace": trace}

    def _route_decision(self, state: AgentState) -> str:
        return {"research": "wiki", "math": "math", "chat": "chat"}.get(
            state["plan"]["task_type"], "chat"
        )

    def _conditional_summarizer(self, state: AgentState) -> AgentState:
        """Ã–zetlemeyi plan kontrolÃ¼ne gÃ¶re uygula veya atla."""
        if state["plan"].get("requires_summary") and state.get("wiki_raw"):
            return self.summarizer.run(state)
        trace = state["execution_trace"]
        trace.append(SystemLogger.log("summarizer", "Ã–zetleme atlandÄ± (gerekmedi)"))
        return {**state, "wiki_summary": None, "execution_trace": trace}

    def _chat_node(self, state: AgentState) -> AgentState:
        """Chat iÃ§in ayrÄ± dÃ¼ÄŸÃ¼m (doÄŸrudan answer_gen'e geÃ§iyor)."""
        return state

    def _qa_decision(self, state: AgentState) -> str:
        if state.get("final_answer"):
            return "approved"
        return "retry" if state.get("retry_count", 0) <= MAX_RETRY_ATTEMPTS else "approved"

    # â”€â”€ Sorgu Ä°ÅŸleme â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def process_query(self, query: str) -> AgentState:
        session_id = str(uuid.uuid4())[:8]
        SystemLogger.header(f"YENÄ° SORGU  [oturum: {session_id}]")
        SystemLogger.log("system", f"Sorgu: {query}")

        initial: AgentState = {
            "session_id": session_id,
            "user_query": query,
            "conversation_history": self.memory.as_list(),
            "plan": None,
            "wiki_raw": None,
            "wiki_summary": None,
            "math_result": None,
            "draft_answer": None,
            "final_answer": None,
            "qa_report": None,
            "retry_count": 0,
            "execution_trace": [],
            "error_log": [],
        }

        result: AgentState = self.app.invoke(initial)

        # HafÄ±zayÄ± gÃ¼ncelle
        self.memory.add("user", query)
        self.memory.add("assistant", result.get("final_answer", ""))
        SystemLogger.log("memory", f"HafÄ±za gÃ¼ncellendi ({len(self.memory.as_list())} tur)")

        return result


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SonuÃ§ YazdÄ±rÄ±cÄ±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def print_result(result: AgentState):
    """Ä°ÅŸlenmiÅŸ sonucu formatlÄ± ÅŸekilde ekrana yaz."""
    SystemLogger.separator("CEVAP")
    print(textwrap.fill(result.get("final_answer", "Cevap Ã¼retilemedi."), width=90))

    # Wikipedia kaynaÄŸÄ±
    wiki = result.get("wiki_raw")
    if wiki:
        SystemLogger.separator("KAYNAK")
        print(f"  BaÅŸlÄ±k : {wiki['title']}")
        print(f"  URL    : {wiki['url']}")

    # QA Raporu
    qa = result.get("qa_report")
    if qa:
        SystemLogger.separator("KALÄ°TE RAPORU")
        score = qa.get("quality_score", "?")
        approved = "âœ… OnaylÄ±" if qa.get("approved") else "âš ï¸ OnaysÄ±z"
        print(f"  Skor   : {score}/10  |  Durum: {approved}")
        if qa.get("issues"):
            print(f"  Sorunlar: {', '.join(qa['issues'])}")
        if qa.get("reasoning"):
            print(f"  GerekÃ§e: {qa['reasoning']}")

    # YÃ¼rÃ¼tme Ã¶zeti
    trace = result.get("execution_trace", [])
    SystemLogger.separator("YÃœRÃœTME Ä°ZÄ°")
    for i, step in enumerate(trace, 1):
        print(f"  {i:2d}. {step}")

    errors = result.get("error_log", [])
    if errors:
        SystemLogger.separator("HATALAR")
        for e in errors:
            print(f"  âš ï¸  {e}")

    print("â•" * 70 + "\n")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# EtkileÅŸimli Ã‡alÄ±ÅŸma Modu
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_interactive():
    SystemLogger.header("ENDÃœSTRÄ°YEL Ã‡OKLU-AJAN SÄ°STEMÄ°  v2.0")
    print("  BileÅŸenler: Planner Â· Wiki Â· Summarizer Â· Math Â· Chat Â· QA Checker")
    print("  Model     :", MODEL_ID)
    print()

    SystemLogger.log("system", "Model yÃ¼kleniyorâ€¦")
    tokenizer, model = ModelLoader.load()
    llm_engine   = LLMEngine(tokenizer, model)
    wiki_searcher = WikipediaSearcher()
    memory       = ConversationMemory(window=MEMORY_WINDOW)
    orchestrator = AgentOrchestrator(llm_engine, wiki_searcher, memory)

    SystemLogger.log("ok", "Sistem hazÄ±r. Sorunuzu yazÄ±n (Ã§Ä±kmak iÃ§in boÅŸ Enter).\n")

    while True:
        try:
            user_input = input("ğŸ§‘  Sorgu: ").strip()
        except (KeyboardInterrupt, EOFError):
            print()
            break

        if not user_input:
            SystemLogger.log("system", "Oturum kapatÄ±ldÄ±. GÃ¼le gÃ¼le!")
            break

        result = orchestrator.process_query(user_input)
        print_result(result)


if __name__ == "__main__":
    run_interactive()
